{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c431881-4ec5-4ec5-8fc3-a0ab21dffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56730e2-164e-4e91-8828-3b8dc36bb9fb",
   "metadata": {},
   "source": [
    "## Gpytorch/MLP插值\n",
    "\n",
    "### 所有原始训练数据从Lasair API获取\n",
    "#### All of the original training data are obtained from the Lasair API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4942d9-6238-4bc3-9621-396f97e09000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_multiband_gp_interpolate(\n",
    "    g_time, g_flux, r_time, r_flux,\n",
    "    new_time_g, new_time_r,\n",
    "    epochs=1000,\n",
    "    device=\"cuda\",\n",
    "    fallback_threshold=0.95,\n",
    "    patience=200,\n",
    "    min_delta=1e-3,\n",
    "    loss_threshold_for_accept=99,  # <<< 新增：GP 收敛质量标准\n",
    "    verbose=True\n",
    "):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import gpytorch\n",
    "    #from interpolate_with_mlp import interpolate_with_mlp  # 确保你实现了这个函数\n",
    "\n",
    "    # 预测退化判断函数\n",
    "    def prediction_is_almost_constant(pred_values, tolerance=1e-2):\n",
    "        return np.std(pred_values) < tolerance\n",
    "\n",
    "\n",
    "    class MultibandGPModel(gpytorch.models.ExactGP):\n",
    "        def __init__(self, train_x, train_y, likelihood):\n",
    "            super().__init__(train_x, train_y, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=2)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            mean_x = self.mean_module(x)\n",
    "            covar_x = self.covar_module(x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    # 1. 数据拼接\n",
    "    g_band = np.zeros_like(g_time)\n",
    "    r_band = np.ones_like(r_time)\n",
    "\n",
    "    all_time = np.concatenate([g_time, r_time])\n",
    "    all_flux = np.concatenate([g_flux, r_flux])\n",
    "    all_band = np.concatenate([g_band, r_band])\n",
    "\n",
    "    train_x_np = np.stack([all_time, all_band], axis=-1)\n",
    "    time_min, time_max = train_x_np[:, 0].min(), train_x_np[:, 0].max()\n",
    "    train_x_np[:, 0] = (train_x_np[:, 0] - time_min) / (time_max - time_min + 1e-8)\n",
    "\n",
    "    train_x = torch.tensor(train_x_np, dtype=torch.float32).to(device)\n",
    "    train_y = torch.tensor(all_flux, dtype=torch.float32).to(device)\n",
    "\n",
    "    # 2. 模型初始化\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "    model = MultibandGPModel(train_x, train_y, likelihood).to(device)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    losses = []\n",
    "    converged = False\n",
    "\n",
    "    # 3. 训练过程 + Early Stopping\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        losses.append(current_loss)\n",
    "\n",
    "        if verbose and epoch % 100 == 0:\n",
    "            print(f\"[Multiband GP][Epoch {epoch}] Loss: {current_loss:.4f}\")\n",
    "\n",
    "        if best_loss - current_loss > min_delta:\n",
    "            best_loss = current_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            if verbose:\n",
    "                print(f\"[Multiband GP] 提前早停于第 {epoch} 轮，Best Loss: {best_loss:.4f}\")\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "    # 若未早停，再根据下降程度判断是否算“收敛”\n",
    "    if not converged:\n",
    "        #if losses[-1] < fallback_threshold * losses[0] and losses[-1] <= 0:\n",
    "        if losses[-1] < fallback_threshold * losses[0]:\n",
    "            best_loss = losses[-1]\n",
    "            converged = True\n",
    "        else:\n",
    "            converged = False\n",
    "\n",
    "    # 4. 输入标准化后的时间坐标\n",
    "    new_x_g = np.stack([new_time_g, np.zeros_like(new_time_g)], axis=-1)\n",
    "    new_x_r = np.stack([new_time_r, np.ones_like(new_time_r)], axis=-1)\n",
    "\n",
    "    new_x_g[:, 0] = (new_x_g[:, 0] - time_min) / (time_max - time_min + 1e-8)\n",
    "    new_x_r[:, 0] = (new_x_r[:, 0] - time_min) / (time_max - time_min + 1e-8)\n",
    "\n",
    "    # 5. 判断是否使用 GP 插值或 fallback 到 MLP\n",
    "    if converged and best_loss < loss_threshold_for_accept:\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            new_x_g_tensor = torch.tensor(new_x_g, dtype=torch.float32).to(device)\n",
    "            new_x_r_tensor = torch.tensor(new_x_r, dtype=torch.float32).to(device)\n",
    "\n",
    "            pred_g = likelihood(model(new_x_g_tensor)).mean.cpu().numpy()\n",
    "            pred_r = likelihood(model(new_x_r_tensor)).mean.cpu().numpy()\n",
    "\n",
    "            # ==== 新增判断：预测是否退化为常数 ====\n",
    "        if (prediction_is_almost_constant(pred_g) and\n",
    "            prediction_is_almost_constant(pred_r)):\n",
    "            if verbose:\n",
    "                print(f\"[Multiband GP] 预测退化为均值，Fallback 到 MLP。\")\n",
    "            pred_g = interpolate_with_mlp(np.array(g_time), np.array(g_flux), new_time_g, device=device)\n",
    "            pred_r = interpolate_with_mlp(np.array(r_time), np.array(r_flux), new_time_r, device=device)\n",
    "            return pred_g, pred_r\n",
    "\n",
    "        return pred_g, pred_r\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"[Multiband GP] Fallback 到 MLP。收敛状态: {converged}, 最终 Loss: {best_loss:.4f}\")\n",
    "        pred_g = interpolate_with_mlp(np.array(g_time), np.array(g_flux), new_time_g, device=device)\n",
    "        pred_r = interpolate_with_mlp(np.array(r_time), np.array(r_flux), new_time_r, device=device)\n",
    "        return pred_g, pred_r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3920b07-4174-4b90-8baa-9d3d4e9292ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Label counts:\n",
      "Label 0: 50 samples\n",
      "Label 1: 4448 samples\n",
      "Label 2: 281 samples\n",
      "Label 3: 1388 samples\n",
      "Label 4: 187 samples\n",
      "Label 5: 52 samples\n",
      "Final dataset shape: (6406, 200, 4)\n",
      "Train label distribution: Counter({np.int64(1): 2891, np.int64(3): 902, np.int64(2): 183, np.int64(4): 121, np.int64(5): 34, np.int64(0): 32})\n",
      "Test label distribution: Counter({np.int64(1): 1557, np.int64(3): 486, np.int64(2): 98, np.int64(4): 66, np.int64(0): 18, np.int64(5): 18})\n",
      "(2243, 200, 4)\n",
      "Training Data is Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting data: 100%|████████████████████████████████████████████████████████████████████████| 4163/4163 [23:13:01<00:00, 20.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented counts: Counter({np.int64(1): 11267, np.int64(3): 3906, np.int64(2): 725, np.int64(4): 486, np.int64(5): 147, np.int64(0): 142})\n",
      "(16673, 200, 4)\n",
      "Testing Data is Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting data:  79%|████████████████████████████████████████████████████████▎              | 1779/2243 [9:54:18<2:33:48, 19.89s/it]/data/zhengrf/venv_zrf/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/data/zhengrf/venv_zrf/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/data/zhengrf/venv_zrf/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n",
      "Augmenting data: 100%|████████████████████████████████████████████████████████████████████████| 2243/2243 [12:26:21<00:00, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented counts: Counter({np.int64(1): 6086, np.int64(3): 2106, np.int64(2): 385, np.int64(4): 283, np.int64(0): 77, np.int64(5): 73})\n",
      "(9010, 200, 4)\n",
      "Train shape (16673, 200, 4)\n",
      "Test shape (9010, 200, 4)\n",
      "[[ 0.          0.36586493  4.9541551   0.66401565]\n",
      " [ 0.11045209  0.36961544  5.04018572  0.66928136]\n",
      " [ 0.22090417  0.37371883  5.12621633  0.67454064]\n",
      " [ 0.33135626  0.37817287  5.21224695  0.67978984]\n",
      " [ 0.44180835  0.38297313  5.29827756  0.68502575]\n",
      " [ 0.55226043  0.38811189  5.38430818  0.6902445 ]\n",
      " [ 0.66271252  0.39358348  5.4703388   0.69544381]\n",
      " [ 0.77316461  0.39937907  5.55636941  0.70061946]\n",
      " [ 0.8836167   0.40549055  5.64240003  0.70576859]\n",
      " [ 0.99406878  0.41190594  5.72843064  0.71088672]\n",
      " [ 1.10452087  0.418616    5.81446126  0.71597081]\n",
      " [ 1.21497296  0.42560887  5.90049188  0.72101629]\n",
      " [ 1.32542504  0.4328731   5.98652249  0.72602057]\n",
      " [ 1.43587713  0.44039544  6.07255311  0.73097926]\n",
      " [ 1.54632922  0.44816363  6.15858373  0.7358886 ]\n",
      " [ 1.6567813   0.45616525  6.24461434  0.74074477]\n",
      " [ 1.76723339  0.46438643  6.33064496  0.74554312]\n",
      " [ 1.87768548  0.47281399  6.41667557  0.75028086]\n",
      " [ 1.98813756  0.48143351  6.50270619  0.75495338]\n",
      " [ 2.09858965  0.49023208  6.58873681  0.75955653]\n",
      " [ 2.20904174  0.49919564  6.67476742  0.76408619]\n",
      " [ 2.31949383  0.5083096   6.76079804  0.76853848]\n",
      " [ 2.42994591  0.51756084  6.84682865  0.77290964]\n",
      " [ 2.540398    0.5269345   6.93285927  0.77719498]\n",
      " [ 2.65085009  0.53641719  7.01888989  0.78138918]\n",
      " [ 2.76130217  0.54599547  7.1049205   0.78548956]\n",
      " [ 2.87175426  0.55565393  7.19095112  0.78949142]\n",
      " [ 2.98220635  0.56537932  7.27698173  0.79339015]\n",
      " [ 3.09265843  0.57515889  7.36301235  0.79718173]\n",
      " [ 3.20311052  0.58497745  7.44904297  0.80086237]\n",
      " [ 3.31356261  0.59482229  7.53507358  0.80442941]\n",
      " [ 3.4240147   0.60468006  7.6211042   0.80787754]\n",
      " [ 3.53446678  0.61453754  7.70713481  0.81120646]\n",
      " [ 3.64491887  0.62438154  7.79316543  0.81441188]\n",
      " [ 3.75537096  0.63419938  7.87919605  0.81749266]\n",
      " [ 3.86582304  0.64397848  7.96522666  0.8204484 ]\n",
      " [ 3.97627513  0.65370637  8.05125728  0.82327753]\n",
      " [ 4.08672722  0.66337121  8.1372879   0.82598233]\n",
      " [ 4.1971793   0.67296147  8.22331851  0.82856226]\n",
      " [ 4.30763139  0.68246561  8.30934913  0.83102095]\n",
      " [ 4.41808348  0.69187343  8.39537974  0.83335972]\n",
      " [ 4.52853556  0.7011745   8.48141036  0.83558321]\n",
      " [ 4.63898765  0.71035892  8.56744098  0.83769476]\n",
      " [ 4.74943974  0.71941799  8.65347159  0.83969855]\n",
      " [ 4.85989183  0.72834367  8.73950221  0.84160072]\n",
      " [ 4.97034391  0.7371285   8.82553282  0.84340513]\n",
      " [ 5.080796    0.7457661   8.91156344  0.84511966]\n",
      " [ 5.19124809  0.75425094  8.99759406  0.84674799]\n",
      " [ 5.30170017  0.76257902  9.08362467  0.84829879]\n",
      " [ 5.41215226  0.77074528  9.16965529  0.84977794]\n",
      " [ 5.52260435  0.77874655  9.2556859   0.85119253]\n",
      " [ 5.63305643  0.7865808   9.34171652  0.85254979]\n",
      " [ 5.74350852  0.794245    9.42774714  0.85385782]\n",
      " [ 5.85396061  0.80173725  9.51377775  0.8551228 ]\n",
      " [ 5.96441269  0.80905575  9.59980837  0.8563537 ]\n",
      " [ 6.07486478  0.8161974   9.68583898  0.85755837]\n",
      " [ 6.18531687  0.82316333  9.7718696   0.85874295]\n",
      " [ 6.29576896  0.82995021  9.85790022  0.85991669]\n",
      " [ 6.40622104  0.83655787  9.94393083  0.86108649]\n",
      " [ 6.51667313  0.84298438 10.02996145  0.8622604 ]\n",
      " [ 6.62712522  0.8492291  10.11599206  0.86344492]\n",
      " [ 6.7375773   0.85529041 10.20202268  0.86464828]\n",
      " [ 6.84802939  0.86116773 10.2880533   0.86587703]\n",
      " [ 6.95848148  0.86685938 10.37408391  0.86713767]\n",
      " [ 7.06893356  0.87236464 10.46011453  0.86843693]\n",
      " [ 7.17938565  0.87768209 10.54614515  0.86978048]\n",
      " [ 7.28983774  0.88281065 10.63217576  0.87117374]\n",
      " [ 7.40028982  0.88774878 10.71820638  0.87262201]\n",
      " [ 7.51074191  0.89249557 10.80423699  0.87413013]\n",
      " [ 7.621194    0.89705008 10.89026761  0.87570119]\n",
      " [ 7.73164609  0.90140986 10.97629823  0.87733817]\n",
      " [ 7.84209817  0.90557516 11.06232884  0.87904376]\n",
      " [ 7.95255026  0.90954292 11.14835946  0.8808198 ]\n",
      " [ 8.06300235  0.91331321 11.23439007  0.88266534]\n",
      " [ 8.17345443  0.91688478 11.32042069  0.8845821 ]\n",
      " [ 8.28390652  0.92025506 11.40645131  0.88656783]\n",
      " [ 8.39435861  0.92342329 11.49248192  0.88862246]\n",
      " [ 8.50481069  0.9263885  11.57851254  0.8907429 ]\n",
      " [ 8.61526278  0.92914891 11.66454315  0.89292735]\n",
      " [ 8.72571487  0.9317019  11.75057377  0.89517295]\n",
      " [ 8.83616695  0.93404853 11.83660439  0.89747542]\n",
      " [ 8.94661904  0.93618536 11.922635    0.89983094]\n",
      " [ 9.05707113  0.93811136 12.00866562  0.90223628]\n",
      " [ 9.16752322  0.93982536 12.09469623  0.9046858 ]\n",
      " [ 9.2779753   0.94132537 12.18072685  0.90717483]\n",
      " [ 9.38842739  0.94260991 12.26675747  0.90969825]\n",
      " [ 9.49887948  0.94367647 12.35278808  0.91225052]\n",
      " [ 9.60933156  0.94452477 12.4388187   0.91482538]\n",
      " [ 9.71978365  0.94515264 12.52484932  0.91741741]\n",
      " [ 9.83023574  0.94555825 12.61087993  0.92001927]\n",
      " [ 9.94068782  0.94574028 12.69691055  0.92262512]\n",
      " [10.05113991  0.94569719 12.78294116  0.92522782]\n",
      " [10.161592    0.94542825 12.86897178  0.9278208 ]\n",
      " [10.27204409  0.94493127 12.9550024   0.93039638]\n",
      " [10.38249617  0.94420671 13.04103301  0.93294764]\n",
      " [10.49294826  0.94325376 13.12706363  0.935467  ]\n",
      " [10.60340035  0.94207251 13.21309424  0.93794632]\n",
      " [10.71385243  0.94066358 13.29912486  0.94037831]\n",
      " [10.82430452  0.9390285  13.38515548  0.94275498]\n",
      " [10.93475661  0.93716884 13.47118609  0.945068  ]\n",
      " [11.04520869  0.93508863 13.55721671  0.94730902]\n",
      " [11.15566078  0.93279201 13.64324732  0.94947046]\n",
      " [11.26611287  0.93028378 13.72927794  0.95154339]\n",
      " [11.37656495  0.9275701  13.81530856  0.95351887]\n",
      " [11.48701704  0.92465705 13.90133917  0.9553892 ]\n",
      " [11.59746913  0.92155147 13.98736979  0.95714545]\n",
      " [11.70792122  0.9182601  14.0734004   0.9587785 ]\n",
      " [11.8183733   0.91479051 14.15943102  0.96028066]\n",
      " [11.92882539  0.91114932 14.24546164  0.96164238]\n",
      " [12.03927748  0.90734464 14.33149225  0.96285504]\n",
      " [12.14972956  0.90338367 14.41752287  0.96391124]\n",
      " [12.26018165  0.89927316 14.50355349  0.96480048]\n",
      " [12.37063374  0.89502054 14.5895841   0.96551633]\n",
      " [12.48108582  0.89063299 14.67561472  0.96604842]\n",
      " [12.59153791  0.8861174  14.76164533  0.96639049]\n",
      " [12.70199     0.88147986 14.84767595  0.96653366]\n",
      " [12.81244208  0.87672704 14.93370657  0.96646988]\n",
      " [12.92289417  0.87186515 15.01973718  0.96619201]\n",
      " [13.03334626  0.86690223 15.1057678   0.96569389]\n",
      " [13.14379835  0.86184251 15.19179841  0.96496731]\n",
      " [13.25425043  0.85669279 15.27782903  0.96400768]\n",
      " [13.36470252  0.85145825 15.36385965  0.96280783]\n",
      " [13.47515461  0.84614599 15.44989026  0.96136391]\n",
      " [13.58560669  0.84076077 15.53592088  0.95967031]\n",
      " [13.69605878  0.83530986 15.62195149  0.95772386]\n",
      " [13.80651087  0.82979745 15.70798211  0.9555226 ]\n",
      " [13.91696295  0.82423127 15.79401273  0.95306253]\n",
      " [14.02741504  0.81861657 15.88004334  0.9503454 ]\n",
      " [14.13786713  0.81296027 15.96607396  0.94736946]\n",
      " [14.24831921  0.8072685  16.05210457  0.94413716]\n",
      " [14.3587713   0.80154693 16.13813519  0.94065166]\n",
      " [14.46922339  0.79580331 16.22416581  0.93691725]\n",
      " [14.57967548  0.7900452  16.31019642  0.93294048]\n",
      " [14.69012756  0.78427887 16.39622704  0.92872763]\n",
      " [14.80057965  0.77851182 16.48225765  0.92428803]\n",
      " [14.91103174  0.77275187 16.56828827  0.9196322 ]\n",
      " [15.02148382  0.76700586 16.65431889  0.91476935]\n",
      " [15.13193591  0.76128268 16.7403495   0.90971148]\n",
      " [15.242388    0.7555902  16.82638012  0.90447205]\n",
      " [15.35284008  0.74993491 16.91241074  0.89906216]\n",
      " [15.46329217  0.744326   16.99844135  0.89349759]\n",
      " [15.57374426  0.73876989 17.08447197  0.88779062]\n",
      " [15.68419634  0.73327386 17.17050258  0.88195729]\n",
      " [15.79464843  0.72784472 17.2565332   0.87601149]\n",
      " [15.90510052  0.72248834 17.34256382  0.86996925]\n",
      " [16.01555261  0.71721035 17.42859443  0.86384499]\n",
      " [16.12600469  0.71201426 17.51462505  0.85765517]\n",
      " [16.23645678  0.70690334 17.60065566  0.85141486]\n",
      " [16.34690887  0.70188034 17.68668628  0.84513986]\n",
      " [16.45736095  0.69694704 17.7727169   0.83884597]\n",
      " [16.56781304  0.69210637 17.85874751  0.83254915]\n",
      " [16.67826513  0.68735898 17.94477813  0.82626384]\n",
      " [16.78871721  0.68270653 18.03080874  0.82000577]\n",
      " [16.8991693   0.67815089 18.11683936  0.81378984]\n",
      " [17.00962139  0.67369395 18.20286998  0.80763137]\n",
      " [17.12007348  0.66933703 18.28890059  0.80154347]\n",
      " [17.23052556  0.66508281 18.37493121  0.79554051]\n",
      " [17.34097765  0.66093218 18.46096182  0.7896359 ]\n",
      " [17.45142974  0.65688801 18.54699244  0.78384215]\n",
      " [17.56188182  0.65295374 18.63302306  0.77817076]\n",
      " [17.67233391  0.6491307  18.71905367  0.7726326 ]\n",
      " [17.782786    0.6454221  18.80508429  0.76723856]\n",
      " [17.89323808  0.6418314  18.89111491  0.76199585]\n",
      " [18.00369017  0.6383611  18.97714552  0.75691414]\n",
      " [18.11414226  0.63501358 19.06317614  0.75199878]\n",
      " [18.22459434  0.63179266 19.14920675  0.74725533]\n",
      " [18.33504643  0.62870061 19.23523737  0.7426886 ]\n",
      " [18.44549852  0.62574112 19.32126799  0.7383011 ]\n",
      " [18.55595061  0.62291598 19.4072986   0.73409539]\n",
      " [18.66640269  0.62022805 19.49332922  0.73007321]\n",
      " [18.77685478  0.61767954 19.57935983  0.72623557]\n",
      " [18.88730687  0.61527228 19.66539045  0.72258121]\n",
      " [18.99775895  0.61300784 19.75142107  0.71911025]\n",
      " [19.10821104  0.61088765 19.83745168  0.71582049]\n",
      " [19.21866313  0.6089133  19.9234823   0.71271026]\n",
      " [19.32911521  0.60708451 20.00951291  0.70977747]\n",
      " [19.4395673   0.60540152 20.09554353  0.70701855]\n",
      " [19.55001939  0.60386419 20.18157415  0.70443016]\n",
      " [19.66047147  0.60247254 20.26760476  0.70200837]\n",
      " [19.77092356  0.60122454 20.35363538  0.69974804]\n",
      " [19.88137565  0.60011947 20.43966599  0.69764626]\n",
      " [19.99182774  0.59915489 20.52569661  0.69569623]\n",
      " [20.10227982  0.59832907 20.61172723  0.69389391]\n",
      " [20.21273191  0.59763867 20.69775784  0.69223356]\n",
      " [20.323184    0.59708154 20.78378846  0.69070977]\n",
      " [20.43363608  0.59665388 20.86981908  0.68931532]\n",
      " [20.54408817  0.59635204 20.95584969  0.68804681]\n",
      " [20.65454026  0.59617257 21.04188031  0.68689561]\n",
      " [20.76499234  0.59611046 21.12791092  0.68585759]\n",
      " [20.87544443  0.59616196 21.21394154  0.68492532]\n",
      " [20.98589652  0.59632218 21.29997216  0.68409258]\n",
      " [21.0963486   0.5965867  21.38600277  0.6833536 ]\n",
      " [21.20680069  0.59694934 21.47203339  0.682702  ]\n",
      " [21.31725278  0.59740686 21.558064    0.68213141]\n",
      " [21.42770487  0.5979529  21.64409462  0.68163556]\n",
      " [21.53815695  0.59858286 21.73012524  0.68120891]\n",
      " [21.64860904  0.59929085 21.81615585  0.68084544]\n",
      " [21.75906113  0.60007191 21.90218647  0.68053889]\n",
      " [21.86951321  0.60092092 21.98821708  0.68028402]\n",
      " [21.9799653   0.60183203 22.0742477   0.68007535]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy.signal import savgol_filter\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def plot_interpolation_debug(\n",
    "    g_time_sorted, g_flux_sorted,\n",
    "    r_time_sorted, r_flux_sorted,\n",
    "    new_time_g, g_interp,\n",
    "    new_time_r, r_interp,\n",
    "    idx=None, filename=None, save=False,\n",
    "    save_dir=\"debug_plots\", invert_y=True,\n",
    "    label=0\n",
    "):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(g_time_sorted, g_flux_sorted, '.', label='g-band (raw)', alpha=0.6)\n",
    "    plt.plot(r_time_sorted, r_flux_sorted, '.', label='r-band (raw)', alpha=0.6)\n",
    "    plt.plot(new_time_g, g_interp, '-', label='g-band (interp)', linewidth=1.2)\n",
    "    plt.plot(new_time_r, r_interp, '-', label='r-band (interp)', linewidth=1.2)\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Flux\")\n",
    "    plt.legend()\n",
    "\n",
    "    title_str = f\"Sample #{idx}, Label={label}\" if idx is not None else \"\"\n",
    "    if filename is not None:\n",
    "        title_str += f\" | {filename}\"\n",
    "    plt.title(title_str.strip())\n",
    "\n",
    "    if invert_y:\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        import os\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        fname = filename.replace(\".json\", \"\") if filename else f\"sample_{idx}\"\n",
    "        plt.savefig(f\"{save_dir}/{fname}.png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def wavelet_denoise(signal, wavelet='db4', level=2, threshold_scale=1.0):\n",
    "    # 小波分解\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    \n",
    "    # 估算噪声阈值（使用最细层 detail 系数）\n",
    "    sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "    threshold = threshold_scale * sigma\n",
    "\n",
    "    # 软阈值处理高频部分\n",
    "    coeffs_thresh = [coeffs[0]]  # 保留 approximation 部分\n",
    "    for detail in coeffs[1:]:\n",
    "        coeffs_thresh.append(pywt.threshold(detail, threshold, mode='soft'))\n",
    "\n",
    "    # 重构信号\n",
    "    return pywt.waverec(coeffs_thresh, wavelet)\n",
    "\n",
    "# 示例：对 fg 和 fr 平滑\n",
    "def smooth_two_band(tg, fg, tr, fr, wavelet='db4', level=3):\n",
    "    fg_smooth = wavelet_denoise(fg, wavelet=wavelet, level=level)\n",
    "    fr_smooth = wavelet_denoise(fr, wavelet=wavelet, level=level)\n",
    "\n",
    "    # 修剪长度匹配（小波重构后可能略长）\n",
    "    fg_smooth = fg_smooth[:len(fg)]\n",
    "    fr_smooth = fr_smooth[:len(fr)]\n",
    "\n",
    "    return tg, fg_smooth, tr, fr_smooth\n",
    "\n",
    "\n",
    "def fill_data(time_g, flux_g, time_r, flux_r, seq_len=200):\n",
    "    # 创建一个形状为 (seq_len, 4) 的全零数组\n",
    "    filled_data = np.zeros((seq_len, 4))\n",
    "\n",
    "    # 填充 time_g 和 flux_g 到第 1 和 2 维度\n",
    "    filled_data[:len(time_g), 0] = time_g  # 填充 time_g 到第 1 维度\n",
    "    filled_data[:len(flux_g), 1] = flux_g  # 填充 flux_g 到第 2 维度\n",
    "\n",
    "    # 填充 time_r 和 flux_r 到第 3 和 4 维度\n",
    "    filled_data[:len(time_r), 2] = time_r  # 填充 time_r 到第 3 维度\n",
    "    filled_data[:len(flux_r), 3] = flux_r  # 填充 flux_r 到第 4 维度\n",
    "\n",
    "    return filled_data\n",
    "\n",
    "\n",
    "class MLPInterpolator(nn.Module):\n",
    "    def __init__(self, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "\n",
    "class LSTMInterpolator(nn.Module):\n",
    "    def __init__(self, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len=1, input_size=1)\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out)[:, -1, :]  # output shape: (batch, 1)\n",
    "\n",
    "\n",
    "def interpolate_with_mlp(time_array, flux_array, new_time, epochs=2000, lr=1e-3, hidden_size=64, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 去除 NaN\n",
    "    mask = ~np.isnan(flux_array)\n",
    "    x = time_array[mask].reshape(-1, 1)\n",
    "    y = flux_array[mask].reshape(-1, 1)\n",
    "\n",
    "    if len(x) < 3:\n",
    "        return PchipInterpolator(time_array, flux_array)(new_time)\n",
    "\n",
    "    # 归一化\n",
    "    #t_min, t_max = x.min(), x.max()\n",
    "    #x_norm = (x - t_min) / (t_max - t_min)\n",
    "    #new_time_norm = (new_time.reshape(-1, 1) - t_min) / (t_max - t_min)\n",
    "\n",
    "    # 新 Gaussian 归一化\n",
    "    t_mean, t_std = x.mean(), max(x.std(), 1e-3)\n",
    "    x_norm = (x - t_mean) / t_std\n",
    "    new_time_norm = (new_time.reshape(-1, 1) - t_mean) / t_std\n",
    "\n",
    "    y_mean, y_std = y.mean(), max(y.std(), 1e-3)\n",
    "    y_norm = (y - y_mean) / y_std\n",
    "\n",
    "    x_tensor = torch.tensor(x_norm, dtype=torch.float32, device=device)\n",
    "    y_tensor = torch.tensor(y_norm, dtype=torch.float32, device=device)\n",
    "\n",
    "    model = MLPInterpolator(hidden_size=hidden_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_tensor)\n",
    "        loss = loss_fn(output, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 预测\n",
    "    new_time_tensor = torch.tensor(new_time_norm, dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(new_time_tensor).cpu().numpy()\n",
    "\n",
    "    pred = pred_norm * y_std + y_mean\n",
    "    return np.clip(pred.flatten(), 1e-6, np.max(flux_array) * 10)\n",
    "\n",
    "\n",
    "def interpolate_with_lstm(time_array, flux_array, new_time, epochs=2000, lr=1e-3, hidden_size=64, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 去除 NaN\n",
    "    mask = ~np.isnan(flux_array)\n",
    "    x = time_array[mask].reshape(-1, 1)\n",
    "    y = flux_array[mask].reshape(-1, 1)\n",
    "\n",
    "    if len(x) < 3:\n",
    "        return PchipInterpolator(time_array, flux_array)(new_time)\n",
    "\n",
    "    # 高斯归一化\n",
    "    t_mean, t_std = x.mean(), max(x.std(), 1e-3)\n",
    "    x_norm = (x - t_mean) / t_std\n",
    "    new_time_norm = (new_time.reshape(-1, 1) - t_mean) / t_std\n",
    "\n",
    "    y_mean, y_std = y.mean(), max(y.std(), 1e-3)\n",
    "    y_norm = (y - y_mean) / y_std\n",
    "\n",
    "    # 转为 tensor，并增加序列维度\n",
    "    x_tensor = torch.tensor(x_norm[:, None], dtype=torch.float32, device=device)  # (N, 1, 1)\n",
    "    y_tensor = torch.tensor(y_norm, dtype=torch.float32, device=device)           # (N, 1)\n",
    "\n",
    "    model = LSTMInterpolator(hidden_size=hidden_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_tensor)\n",
    "        loss = loss_fn(output, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 预测\n",
    "    new_time_tensor = torch.tensor(new_time_norm.reshape(-1, 1, 1), dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(new_time_tensor).cpu().numpy()\n",
    "\n",
    "    pred = pred_norm * y_std + y_mean\n",
    "    return np.clip(pred.flatten(), 1e-6, np.max(flux_array) * 10)\n",
    "\n",
    "\n",
    "\n",
    "# 将星等转为流量的函数\n",
    "def mag_to_flux(mag, m_ref=22.5):\n",
    "    if float(mag) <= 0:  # 避免无效的星等值\n",
    "        return 0\n",
    "    return 10 ** (0.4 * (m_ref - float(mag)))\n",
    "\n",
    "def magerr_to_fluxerr(flux,magerr):\n",
    "    \n",
    "    return 0.921*flux*magerr\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 切分数据并插值\n",
    "import numpy as np\n",
    "\n",
    "# 修改后的函数\n",
    "def sample_and_process(sequence, target_length=200, time_range=(0, 15)):\n",
    "    time = sequence[:, 0]\n",
    "    g_flux = sequence[:, 1]\n",
    "    r_flux = sequence[:, 2]\n",
    "    \n",
    "    # 超出指定时间范围的部分设定为0\n",
    "    mask = (time >= time_range[0]) & (time <= time_range[1])\n",
    "    sampled_time = time[mask]\n",
    "    sampled_g_flux = g_flux[mask]\n",
    "    sampled_r_flux = r_flux[mask]\n",
    "\n",
    "    # 创建一个全为0的目标数组，长度为target_length，列数为5（包括时间、g_flux、r_flux）\n",
    "    result = np.zeros((target_length, 3))\n",
    "\n",
    "    # 将有效时间数据映射到0到target_length的范围\n",
    "    if len(sampled_time) > 0:\n",
    "        # 计算时间的线性映射\n",
    "        time_min, time_max = sampled_time.min(), sampled_time.max()\n",
    "        time_scaled = (sampled_time - time_min) / (time_max - time_min) * (target_length - 1)\n",
    "\n",
    "        # 将时间对应的索引映射到目标数组\n",
    "        time_indices = np.round(time_scaled).astype(int)\n",
    "\n",
    "        # 填充时间、g_flux和r_flux\n",
    "        for i, idx in enumerate(time_indices):\n",
    "            result[idx, 0] = sampled_time[i]  # 填充时间\n",
    "            result[idx, 1] = sampled_g_flux[i]  # 填充g_flux\n",
    "            result[idx, 2] = sampled_r_flux[i]  # 填充r_flux\n",
    "\n",
    "    # 对所有行进行排序，按时间升序排列\n",
    "    result = result[result[:, 0].argsort()]\n",
    "\n",
    "    # 标准化g_flux和r_flux\n",
    "    max_flux = max(result[:, 1].max(), result[:, 2].max())\n",
    "    if max_flux > 0:  # 防止除以零\n",
    "        result[:, 1] /= max_flux\n",
    "        result[:, 2] /= max_flux\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def sample_and_interpolate(sequence, target_length=200,plot=False, invert_y=True,max_plots=5,label=None):\n",
    "    #在这里，选择g，r波段分别插值，不再进行统一插值了\n",
    "    g_time = sequence[:, 0]\n",
    "    g_flux = sequence[:, 1]\n",
    "    r_time = sequence[:, 2]\n",
    "    r_flux = sequence[:, 3]\n",
    "    \n",
    "    max_time_range = max(max(g_time), max(r_time)) - min(min(r_time), min(g_time))\n",
    "    \n",
    "    \n",
    "    # 如果时间跨度太小，直接返回全零数组\n",
    "    if max_time_range <= 0:\n",
    "        print(max_time_range)\n",
    "        return np.zeros((target_length, 5))  # 返回全零数组，长度为目标长度\n",
    "        \n",
    "    \n",
    "    # 切分数据为多个阶段（按时间百分比）\n",
    "    max_time = max(max(g_time), max(r_time))\n",
    "    #print(max_time)\n",
    "    gx = g_time[g_time>0]\n",
    "    min_time = np.min(gx)\n",
    "\n",
    "\n",
    "    stages = [\n",
    "\n",
    "        (-np.inf, min_time+0.2*(max_time-min_time)),\n",
    "       \n",
    "        (-np.inf, min_time+0.4*(max_time-min_time)),\n",
    "        \n",
    "        (-np.inf, min_time+0.6*(max_time-min_time)),\n",
    "        \n",
    "        (-np.inf, min_time+0.8*(max_time-min_time)),\n",
    "        \n",
    "        (-np.inf, np.inf)\n",
    "    ]\n",
    "    \n",
    "    augmented_sequences = []\n",
    "    plot_count=0\n",
    "    \n",
    "    for start, end in stages:\n",
    "        # 根据时间范围筛选子序列\n",
    "        #print('seq - sub01')\n",
    "        mask_g = (g_time >= start) & (g_time <= end) & (g_time != 0)\n",
    "        mask_r = (r_time >= start) & (r_time <= end) & (r_time != 0)\n",
    "        sampled_g_time = g_time[mask_g]\n",
    "        sampled_g_flux = g_flux[mask_g]\n",
    "        sampled_r_time = r_time[mask_r]\n",
    "        sampled_r_flux = r_flux[mask_r]\n",
    "\n",
    "        # 只保留非零数据点\n",
    "        non_zero_g_flux = sampled_g_flux[sampled_g_flux != 0]\n",
    "        non_zero_r_flux = sampled_r_flux[sampled_r_flux != 0]\n",
    "\n",
    "        # 如果非零数值过少（不足三个数据点），跳过\n",
    "        if len(non_zero_g_flux) < 4 or len(non_zero_r_flux) < 4:\n",
    "            continue\n",
    "        \n",
    "        # 归一化flux\n",
    "        max_flux_fix = max(np.max(non_zero_g_flux), np.max(non_zero_r_flux))\n",
    "        sampled_g_flux = sampled_g_flux \n",
    "        sampled_r_flux = sampled_r_flux \n",
    "        s1=min( np.min(sampled_r_time),np.min(sampled_g_time))\n",
    "        \n",
    "        \n",
    "        sampled_g_time_1 = sampled_g_time.copy()\n",
    "        sampled_r_time_1 = sampled_r_time.copy()\n",
    "        sampled_r_flux_1 = sampled_r_flux.copy()\n",
    "        sampled_g_flux_1 = sampled_g_flux.copy()\n",
    "\n",
    "        s3 = max(np.min(sampled_g_time_1),np.min(sampled_r_time_1)) #max min time         \n",
    "        s4 = min(np.max(sampled_g_time_1),np.max(sampled_r_time_1)) #min max time         \n",
    "        s2 = max(np.max(sampled_g_flux_1),np.max(sampled_r_flux_1)) #max max flux\n",
    "        s7 = min(np.min(sampled_g_flux_1),np.min(sampled_r_flux_1)) #min min flux\n",
    "        \n",
    "       \n",
    "\n",
    "        if len(sampled_g_flux) < 4 or len(sampled_r_flux) < 4:             \n",
    "            continue\n",
    "\n",
    "       \n",
    "\n",
    "        tg = np.linspace(np.min(sampled_g_time_1), np.max(sampled_g_time_1), target_length)\n",
    "        tr = np.linspace(np.min(sampled_r_time_1), np.max(sampled_r_time_1), target_length)\n",
    "\n",
    "        \n",
    "        \n",
    "        upper_limit_flux = 10 * max(np.max(sampled_g_flux),np.max(sampled_r_flux))\n",
    "        lower_limit_flux = 1e-6\n",
    "\n",
    "        sampled_g_flux = (sampled_g_flux - 0 ) /(s2 - 0)\n",
    "        sampled_r_flux = (sampled_r_flux - 0 ) /(s2 - 0)\n",
    "\n",
    "        '''\n",
    "        for i in range(len(sampled_g_flux)):\n",
    "            sampled_g_flux[i] = 10**sampled_g_flux[i]\n",
    "\n",
    "        for i in range(len(sampled_r_flux)):\n",
    "            sampled_r_flux[i] = 10**sampled_r_flux[i]\n",
    "        '''\n",
    "        tg = tg-s1\n",
    "        tr = tr-s1\n",
    "        #tt = tt - s1\n",
    "        sampled_g_time = sampled_g_time - s1\n",
    "        sampled_r_time = sampled_r_time - s1\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        sampled_g_time_1, sampled_g_flux_1, sampled_r_time_1,sampled_r_flux_1 = sampled_g_time, sampled_g_flux, sampled_r_time,sampled_r_flux\n",
    "       \n",
    "\n",
    "        try:\n",
    "            g_interp, r_interp = safe_multiband_gp_interpolate(\n",
    "                                        sampled_g_time, sampled_g_flux,\n",
    "                                        sampled_r_time, sampled_r_flux,\n",
    "                                        tg, tr,\n",
    "                                        epochs=1000,\n",
    "                                        device=\"cuda\",\n",
    "                                        min_delta=1e-3,\n",
    "                                        fallback_threshold = 0.1,\n",
    "                                        loss_threshold_for_accept=99,  # <<< 新增：GP 收敛质量标准\n",
    "                                        verbose=False\n",
    "                                    )\n",
    "        except RuntimeError as e:\n",
    "            print('GP Process Facing Uncorrectable Error, MLP Instead...')\n",
    "            g_interp = interpolate_with_mlp(np.array(sampled_g_time), np.array(sampled_g_flux), tg,device=\"cuda\",epochs=1000)\n",
    "            r_interp = interpolate_with_mlp(np.array(sampled_r_time), np.array(sampled_r_flux), tr,device=\"cuda\",epochs=1000)\n",
    "        \n",
    "                \n",
    "        \n",
    "        fg = np.clip(g_interp,lower_limit_flux, upper_limit_flux)\n",
    "        fr = np.clip(r_interp,lower_limit_flux, upper_limit_flux)\n",
    "\n",
    "        #f_max = max(np.max(fg),np.max(fr))\n",
    "        \n",
    "        #fg = fg/f_max;fr = fr/f_max\n",
    "        \n",
    "        #小波变换\n",
    "        #tg, fg, tr, fr = smooth_two_band(tg, fg, tr, fr)\n",
    "\n",
    "        #SV平滑\n",
    "        #fg = savgol_filter(fg, window_length=30, polyorder=2)\n",
    "        #fr = savgol_filter(fr, window_length=30, polyorder=2)\n",
    "\n",
    "        # 组合插值结果\n",
    "        augmented_sequences.append(np.vstack((tg, fg, tr, fr)).T)\n",
    "        #print(start,end)\n",
    "\n",
    "        # 只绘制前 max_plots 次\n",
    "\n",
    "        #tg = [];tr = [];fg = [];fr = []\n",
    "\n",
    "        '''\n",
    "        if plot and plot_count < max_plots:\n",
    "            #print(tg,fg)\n",
    "            plot_interpolation_debug(\n",
    "                sampled_g_time, sampled_g_flux,\n",
    "                sampled_r_time, sampled_r_flux,\n",
    "                tg, fg,\n",
    "                tr, fr,\n",
    "                idx=plot_count,\n",
    "                invert_y=False,\n",
    "                label=str(label)\n",
    "            )\n",
    "            plot_count += 1\n",
    "        else:\n",
    "            stop\n",
    "        '''\n",
    "\n",
    "    \n",
    "    return augmented_sequences\n",
    "\n",
    "\n",
    "# 扩充样本数据（随机增强机制）\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def augment_samples(data, labels, augment_times=1):\n",
    "    augmented_data = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    total_samples = len(data)\n",
    "\n",
    "    for i in tqdm(range(total_samples), desc=\"Augmenting data\"):\n",
    "        sequence = data[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        augmented_sequences = sample_and_interpolate(sequence, plot=True, label=label)\n",
    "\n",
    "        for augmented_sequence in augmented_sequences:\n",
    "            if len(augmented_sequence) > 0 and np.array(augmented_sequence).shape[0] == 200:\n",
    "                augmented_data.append(augmented_sequence)\n",
    "                augmented_labels.append(label)\n",
    "\n",
    "    print(f\"Augmented counts: {Counter(augmented_labels)}\")\n",
    "    print(np.array(augmented_data).shape)\n",
    "    return np.array(augmented_data), np.array(augmented_labels)\n",
    "\n",
    "\n",
    "\n",
    "# 修改后的主函数\n",
    "def load_and_modify_json(directories, labels, m_ref=22.5, target_counts=None,train_ratio = 0.6):\n",
    "    data = []\n",
    "    all_labels = []\n",
    "    label_count = Counter()\n",
    "    processed = 0\n",
    "    for directory, label in zip(directories, labels):\n",
    "        for file in os.listdir(directory):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            if os.path.isfile(file_path) and file.endswith('.json'):\n",
    "                with open(file_path, 'r') as f:\n",
    "                   try: \n",
    "                        processed +=1\n",
    "                        #print(f'processing No.{processed} Light curve')\n",
    "                        json_data = json.load(f)\n",
    "\n",
    "                        # 处理格式1（candidates数组）\n",
    "                        if isinstance(json_data, dict) and \"candidates\" in json_data:\n",
    "                            candidates = json_data[\"candidates\"]\n",
    "                            sequence = []\n",
    "                            \n",
    "                            for candidate in candidates:\n",
    "                                if candidate.get(\"isdiffpos\") == 't':\n",
    "                                    jd = candidate.get(\"jd\", 0)\n",
    "                                    mag_g = candidate.get(\"magpsf\") if candidate.get(\"fid\") == 1 else None  # 根据fid选择g波段\n",
    "                                    mag_r = candidate.get(\"magpsf\") if candidate.get(\"fid\") == 2 else None  # 根据fid选择r波段\n",
    "                                    mag_g_err = candidate.get(\"sigmapsf\") if candidate.get(\"fid\") == 1 else None\n",
    "                                    mag_r_err = candidate.get(\"sigmapsf\") if candidate.get(\"fid\") == 2 else None\n",
    "                                    mag_g_zp = candidate.get(\"magzpsci\") if candidate.get(\"fid\") == 1 else None\n",
    "                                    mag_r_zp = candidate.get(\"magzpsci\") if candidate.get(\"fid\") == 2 else None\n",
    "                                    \n",
    "                                    # 仅当有有效的g和r波段数据时才进行赋值\n",
    "                                    if mag_g is not None:\n",
    "                                        mag_g = mag_to_flux(mag_g, m_ref)\n",
    "                                        #mag_g = float(mag_g)\n",
    "                                        flux_g_err = magerr_to_fluxerr(mag_g,mag_g_err)\n",
    "                                    if mag_r is not None:\n",
    "                                        mag_r = mag_to_flux(mag_r, m_ref)\n",
    "                                        #mag_r = float(mag_r)\n",
    "                                        flux_r_err = magerr_to_fluxerr(mag_r,mag_r_err)\n",
    "    \n",
    "                                    sequence.append([jd-2400000.5, mag_g if mag_g is not None else 0, mag_r if mag_r is not None else 0])\n",
    "\n",
    "                        # 处理格式2（数组形式）\n",
    "                        elif isinstance(json_data, list) and \"MJD\" in json_data[0]:\n",
    "                            sequence = []\n",
    "                            for entry in json_data:\n",
    "                                mjd = float(entry.get(\"MJD\", 0))\n",
    "                                if entry['unforced_mag_status']=='positive':\n",
    "                                    if entry[\"filter\"] == \"g\":\n",
    "                                        #mag_g = float(entry.get(\"unforced_mag\", 0))\n",
    "                                        mag_g = mag_to_flux(entry.get(\"unforced_mag\", 0), m_ref)\n",
    "                                        mag_r = 0  # 如果当前是g波段，r波段为0\n",
    "                                    elif entry[\"filter\"] == \"r\":\n",
    "                                        #mag_r = float(entry.get(\"unforced_mag\", 0))\n",
    "                                        mag_r = mag_to_flux(entry.get(\"unforced_mag\", 0), m_ref)\n",
    "                                        mag_g = 0  # 如果当前是r波段，g波段为0\n",
    "                                    else:\n",
    "                                        continue  # 如果不是g或r波段则跳过\n",
    "                                else:\n",
    "                                    continue\n",
    "\n",
    "                                sequence.append([mjd, mag_g, mag_r])\n",
    "\n",
    "                        else:\n",
    "                            print(f\"Skipping file {file_path}: unexpected format.\")\n",
    "                            continue\n",
    "\n",
    "                        # 将序列转换为numpy数组\n",
    "                        sequence = np.array(sequence)\n",
    "                        if sequence.shape[0]!=0 and sequence.shape[0]>10:\n",
    "                            \n",
    "                            pass\n",
    "                        else:\n",
    "                            #print('An error file occurs')\n",
    "                            continue\n",
    "                        # 处理排序和插值\n",
    "                        # 分别获取 g 波段和 r 波段的时间和流量\n",
    "                        g_time = sequence[:, 0][sequence[:, 1] > 0]\n",
    "                        g_flux = sequence[:, 1][sequence[:, 1] > 0]\n",
    "                        r_time = sequence[:, 0][sequence[:, 2] > 0]\n",
    "                        r_flux = sequence[:, 2][sequence[:, 2] > 0]\n",
    "\n",
    "                        # 对 g 和 r 波段的时间和流量进行排序\n",
    "                        sorted_g_indices = np.argsort(g_time)  # 获取 g_time 排序的索引\n",
    "                        g_time_sorted = g_time[sorted_g_indices]  # 根据排序的索引排序 g_time\n",
    "                        g_flux_sorted = g_flux[sorted_g_indices]  # 同时排序 g_flux\n",
    "                        \n",
    "                        sorted_r_indices = np.argsort(r_time)  # 获取 r_time 排序的索引\n",
    "                        r_time_sorted = r_time[sorted_r_indices]  # 根据排序的索引排序 r_time\n",
    "                        r_flux_sorted = r_flux[sorted_r_indices]  # 同时排序 r_flux\n",
    "                        \n",
    "                       \n",
    "                        \n",
    "                        # 删除 g 和 r 波段中时间相同的点\n",
    "                        unique_g_times = []\n",
    "                        unique_g_flux = []\n",
    "                        unique_r_times = []\n",
    "                        unique_r_flux = []\n",
    "                        \n",
    "                        for g_time_val, g_flux_val in zip(g_time_sorted, g_flux_sorted):\n",
    "                            if g_time_val not in unique_g_times:\n",
    "                                unique_g_times.append(g_time_val)\n",
    "                                unique_g_flux.append(g_flux_val)\n",
    "                        \n",
    "                        for r_time_val, r_flux_val in zip(r_time_sorted, r_flux_sorted):\n",
    "                            if r_time_val not in unique_r_times:\n",
    "                                unique_r_times.append(r_time_val)\n",
    "                                unique_r_flux.append(r_flux_val)\n",
    "                        \n",
    "                        # 重新组合已去除重复时间点的 g 和 r 波段\n",
    "                        g_time_sorted = np.array(unique_g_times)\n",
    "                        g_flux_sorted = np.array(unique_g_flux)\n",
    "                        r_time_sorted = np.array(unique_r_times)\n",
    "                        r_flux_sorted = np.array(unique_r_flux)\n",
    "\n",
    "                        #try:\n",
    "                        \n",
    "                        if len(g_time_sorted)>3 and len(r_time_sorted)>3:\n",
    "                            # 使用 g 和 r 波段时间的最大和最小值设置为时间的起止点\n",
    "                            min_time = min(min(g_time_sorted), min(r_time_sorted))\n",
    "                            max_time = max(max(g_time_sorted), max(r_time_sorted))\n",
    "\n",
    "                            min_max_time = min(max(g_time_sorted), max(r_time_sorted))\n",
    "                            max_min_time = max(min(g_time_sorted), min(r_time_sorted))\n",
    "\n",
    "                            tg = np.zeros(200);tr = np.zeros(200);fg = np.zeros(200);fr = np.zeros(200)\n",
    "                            if len(g_time_sorted)<=200:\n",
    "                                for i in range(len(g_time_sorted)):\n",
    "                                    tg[i] = g_time_sorted[i]\n",
    "                                    fg[i] = g_flux_sorted[i]\n",
    "                            else:\n",
    "                                for i in range(200):\n",
    "                                    tg[i] = g_time_sorted[i]\n",
    "                                    fg[i] = g_flux_sorted[i]\n",
    "\n",
    "                            if len(r_time_sorted)<=200:\n",
    "                                for i in range(len(r_time_sorted)):\n",
    "                                    tr[i] = r_time_sorted[i]\n",
    "                                    fr[i] = r_flux_sorted[i]\n",
    "                            else:\n",
    "                                for i in range(200):\n",
    "                                    tr[i] = r_time_sorted[i]\n",
    "                                    fr[i] = r_flux_sorted[i]\n",
    "\n",
    "                            #import matplotlib.pyplot as plt\n",
    "\n",
    "                            #plt.plot(g_time_sorted,g_flux_sorted,'.')\n",
    "                            #plt.plot(r_time_sorted,r_flux_sorted,'.')\n",
    "                            #plt.plot(new_time_g,g_interp)\n",
    "                            #plt.plot(new_time_r,r_interp)\n",
    "                            \n",
    "                            #stop\n",
    "                            #if g_flux_sorted[-1]<np.max(g_flux_sorted) and r_flux_sorted[-1]<np.max(r_flux_sorted):\n",
    "                             \n",
    "                            sequence_full = fill_data(tg, fg, tr,fr)\n",
    "\n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                            # 填充或截断序列到最大长度200\n",
    "                            if len(sequence) < 200:\n",
    "                                padding = np.zeros((200 - len(sequence), 3))\n",
    "                                sequence = np.vstack((sequence, padding))\n",
    "                            elif len(sequence) > 200:\n",
    "                                sequence = sequence[:200]\n",
    "    \n",
    "                            # 如果第二列和第三列都为0，将第一列的值也设为0\n",
    "                            for row in sequence:\n",
    "                                if row[1] == 0 and row[2] == 0:\n",
    "                                    row[0] = 0  # 将第一列也设为0\n",
    "    \n",
    "                            data.append(sequence_full)\n",
    "                            all_labels.append(label)\n",
    "                            label_count[label] += 1  # 更新标签计数\n",
    "                        #except SyntaxError:\n",
    "                            #print('>>')\n",
    "                            pass\n",
    "                   #except (json.JSONDecodeError, ValueError):\n",
    "                   except SyntaxError:\n",
    "                        print(f\"Skipping file {file_path}: unable to decode JSON or invalid data.\")    \n",
    "\n",
    "    print(\"Initial Label counts:\")\n",
    "    for label, count in label_count.items():\n",
    "        print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "    print(f\"Final dataset shape: {np.array(data).shape}\")\n",
    "   \n",
    "    labels = np.array(all_labels)\n",
    "    data = np.array(data)\n",
    "    # 扩充样本,仅针对训练集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=(1-train_ratio), stratify=labels, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Train label distribution:\", Counter(y_train))\n",
    "    print(\"Test label distribution:\", Counter(y_test))\n",
    "\n",
    "    print(X_test.shape)\n",
    "    print(f\"Training Data is Augmenting...\")\n",
    "    X_train, y_train = augment_samples(np.array(X_train), np.array(y_train), augment_times=1)\n",
    "    np.save(\"X_train.npy\", X_train)\n",
    "    np.save(\"y_train.npy\", y_train)\n",
    "    \n",
    "    print(f\"Testing Data is Augmenting...\")\n",
    "    X_test,y_test = augment_samples(np.array(X_test), np.array(y_test),augment_times=1)\n",
    "    np.save(\"X_test.npy\", X_test)\n",
    "    np.save(\"y_test.npy\", y_test)\n",
    "\n",
    "    print(\"Train shape\",X_train.shape)\n",
    "    print(\"Test shape\",X_test.shape)\n",
    "\n",
    "    return np.array(data),X_train\n",
    "\n",
    "\n",
    "# 保存数据\n",
    "\n",
    "\n",
    "directories = ['../ZTF-TDE/','../ZTF_SN_total/SN Ia/','../ZTF SN Ib Ic','../ZTF_SN_total/SN II_all/','../ZTF SLSN/','../ZTF AGN/']\n",
    "               \n",
    "\n",
    "labels = [0,1,2,3,4,5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target_counts = {0: 1000, 1: 10000, 2: 10000}  # 每个类别的目标样本数，但是目前来说是摆设\n",
    "\n",
    "# 加载和扩充数据\n",
    "data,X_train= load_and_modify_json(directories, labels, target_counts=target_counts,train_ratio=0.65)\n",
    "\n",
    "\n",
    "# 检查数据\n",
    "\n",
    "print(X_train[1])\n",
    "\n",
    "#print(np.max(data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
